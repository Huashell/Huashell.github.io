---
layout: post
title: "raft 日志篇"
date:   2023-11-27
tags: [geek]
comments: true
author: ddd
toc: true
---



我们已经完成了raft中的选举部分内容，接下来是日志部分。



<!-- more -->

## 开始

​	我们已经完成了raft算法中的选举部分，接下写的是log本分的代码。先看我们的任务

~~~markdown
Implement the leader and follower code to append new log entries
~~~



​	显而易见，我们接下来要改进AppendEntries的rpc调用了。

​	首先根据论文，先为我们的raft补充2个成员

~~~go
type Raft struct {
	//...其他成员
    lastApplied  int
	nextIndex  []int
	matchIndex []int

	
}
~~~



成员作用如下

#### lastApplied 

应用于状态机的最高日志条目的索引（初始化为0，单调增加）

#### nextIndex[] 

对于每台服务器，发送到该服务器的下一个日志条目的索引（初始化为leader last log index+1）

#### matchIndex[] 

对于每个服务器，已知要在服务器上复制的最高日志条目的索引（初始化为0，单调增加）

lastApplid指上一个提交的log的index，nextIndex[i]指的是下标为i的主机下一个要获取的log的index号，matchIndex[i]指的是下标为i的主机已知的最新log的index

反复阅读论文，可以总结出算法设计逻辑如下日志复制的逻辑如下:

- **`leader`视角**

1. `client`想集群的一个节点发送的命令, 如果不是`leader`, `follower`会通过心跳得知`leader`并返回给`client`
2. `leader`收到了命令, 将其构造为一个日志项, 添加当前节点的`currentTerm`为日志项的`Term`, 并将其追加到自己的`log`中
3. `leader`发送`AppendEntries RPC`将`log`复制到所有的节点, `AppendEntries RPC`需要增加`PrevLogIndex`、`PrevLogTerm`以供`follower`校验, 其中`PrevLogIndex`、`PrevLogTerm`由`nextIndex`确定
4. 如果`RPC`返回了成功, 则更新`matchIndex`和`nextIndex`, 同时寻找一个满足过半的`matchIndex[i] >= N`的索引位置`N`, 将其更新为自己的`commitIndex`, 并提交直到`commitIndex`部分的日志项
5. 如果`RPC`返回了失败, 且伴随的的`Term`更大, 表示自己已经不是`leader`了, 将自身的角色转换为`Follower`, 并更新`currentTerm`和`votedFor`, 重启计时器
6. 如果`RPC`返回了失败, 且伴随的的`Term`和自己的`currentTerm`相同, 将`nextIndex`自减再重试

- **`follower`视角**

1. `follower`收到`AppendEntries RPC`后,`currentTerm`不匹配直接告知更新的`Term`, 并返回`false`
2. `follower`收到`AppendEntries RPC`后, 通过`PrevLogIndex`、`PrevLogTerm`可以判断出"`leader`认为自己`log`的结尾位置"是否存在并且`Term`匹配, 如果不匹配, 返回`false`并不执行操作;
3. 如果上述位置的信息匹配, 则需要判断插入位置是否有旧的日志项, 如果有, 则向后将`log`中冲突的内容清除
4. 将`RPC`中的日志项追加到`log`中
5. 根据`RPC`的传入参数更新`commitIndex`, 并提交直到`commitIndex`部分的日志项

​	首先从leader视角出发，每次添加log时都要调用start函数：

```go
func (rf *Raft) Start(command interface{}) (int, int, bool) {
	index := -1
	term := -1
	isLeader := true

	// Your code here (2B).

	rf.mu.Lock()
	defer rf.mu.Unlock()
	if rf.state != LEADER {
		return -1, -1, false
	}

	newLog := rf.appendLog(command) // 日志队列中加入一条新log
	index = newLog.Index
	term = rf.currentTerm         // 当前的任期
	isLeader = rf.state == LEADER // 是否是leader

	rf.sendEntries()
	return index, term, isLeader
}
```





​	调用sendEntries时，用peer遍历raft中的peers成员，然后构造一个新的用于SppendEntriesArgs的rpc调用的参数。然后调用sendAppendEntries函数，该函数用于call一个指定peer的rpc调用。

```go
args := rf.newAppendEntriesArgs(peer)
rf.mu.Unlock()

reply := &AppendEntriesReply{}
if rf.sendAppendEntries(peer, args, reply) {
	rf.mu.Lock()
	rf.handleAppendEntriesResponse(peer, args, reply)
	rf.mu.Unlock()
}
```

​	

​	我们直接看核心代码，AppendEntries的rpc调用

```go

func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) {
	rf.mu.Lock()
	defer rf.mu.Unlock()

	if args.Term < rf.currentTerm {
		reply.Term = rf.currentTerm
		reply.Success = false
		return
	}

	rf.changeState(FOLLOWER)
	rf.currentTerm = args.Term

	
	if args.PreLogIndex < rf.getFirstLog().Index {
		reply.Success, reply.Term = false, 0
		return
	}

	if args.PreLogIndex > rf.getLastLog().Index || rf.logs[args.PreLogIndex-rf.getFirstLog().Index].Term != args.PreLogTerm {

		
		reply.Success, reply.Term = false, rf.currentTerm
		lastIndex := rf.getLastLog().Index
		firstIndex := rf.getFirstLog().Index
		if args.PreLogIndex > lastIndex {
			reply.XIndex, reply.XTerm = lastIndex+1, -1
		} else {
			reply.XTerm = rf.logs[args.PreLogIndex-firstIndex].Term

			index := args.PreLogIndex - 1
			for index >= firstIndex && rf.logs[index-firstIndex].Term == reply.XTerm {
				index--
			}
			reply.XIndex = index
		}
		return
	}

	
	firstIndex := rf.cropLogs(args)
	rf.logs = append(rf.logs, args.Logs[firstIndex:]...)
	newCommitIndex := min(args.LeaderCommit, rf.getLastLog().Index)
	
	if newCommitIndex > rf.commitIndex {
		rf.commitIndex = newCommitIndex
		rf.applyMsgCond.Signal()
	}

	reply.Success, reply.Term = true, rf.currentTerm
}

```

​	第一步，比较发送方的最新任期号，如果接受方的任期号更新，就回应一个false，直接结束调用

​	第二步，除掉选举篇中的判断语句，即

```go
if len(args.Logs) == 0 {
	reply.Success = true
	return
}
```

​	原本参数中的Logs为空时代表这是个心跳包，但在日志篇中，leader有义务告知follower自己提交的最新log，如果这里直接返回的话就不能告知follower该提交到哪个log了。

​	第三步，判断发送方的上一条日志索引和接受方的最后一条日志索引是否匹配。如果不匹配，说明发生了冲突，发生冲突的时候一共有三种可能

1. follower中没有preLogIndex对应的日志 那么nextIndex回退到刚好匹配的那个索引

​    2. follower中存在preLogIndex对应的日志 但是任期冲突 那么记录一下follower当前任期的第一条日志索引，leader接收到冲突任期之后判断一下 如果本地存在冲突任期的日志，那么leader应该回退到该任期对应的最后一条日志索引+1

    3. leader接收到冲突任期之后判断一下 如果本地不存在冲突任期的日志，那么

​	第四步，到这时候，说明前面的log都已经对应上了，剩下要做的就是附加日志，并判断最新的日志index是否大于当前实例的提交index，如果是就更换。

   	然后我们来看另一段核心代码，leader的处理结果函数：

```go
func (rf *Raft) handleAppendEntriesResponse(peer int, args *AppendEntriesArgs, reply *AppendEntriesReply) {
	
	if rf.state == LEADER && rf.currentTerm == args.Term {
		if reply.Term > rf.currentTerm {
			rf.currentTerm = reply.Term
			rf.votedFor = -1
			rf.changeState(FOLLOWER)
		} else {
			
			if reply.Success {
				
				rf.matchIndex[peer] = max(rf.matchIndex[peer], args.PreLogIndex+len(args.Logs))
				DPrintf("preLogIndex = %d log length = %d", args.PreLogIndex, len(args.Logs))
				
				rf.nextIndex[peer] = rf.matchIndex[peer] + 1
				DPrintf("leader node {%d} term {%d} update %d nextIndex = %d\n", rf.me, rf.currentTerm, peer, rf.nextIndex[peer])
				
				
				rf.updateLeaderCommitIndex()
			} else if reply.Term == rf.currentTerm {
			
			
			
				firstIndex := rf.getFirstLog().Index
				rf.nextIndex[peer] = max(reply.XIndex, rf.matchIndex[peer]+1)

				if reply.XTerm != -1 {
					
					boundary := max(firstIndex, reply.XIndex)
					for i := args.PreLogIndex; i >= boundary; i-- {
						if rf.logs[i-firstIndex].Term == reply.XTerm {
							rf.nextIndex[peer] = i + 1
							break
						}
					}
					
				}
		
			}
		}

	}
}

```

​	判断任期-》判断rpc调用是否成功-》成功则更新leader的matchIndex数组和nextIndex数组，失败则按照reply中的任期回退（由于我写到这里时，代码事实上已经更新至2d，所以这里的getfirstlog返回的是当前任期的第一个log）-》处理冲突的任期







​	测试通过

```bash
go test -run 2B
Test (2B): basic agreement ...
  ... Passed --   0.5  3   16    4400    3
Test (2B): RPC byte count ...
  ... Passed --   1.4  3   48  113980   11
Test (2B): test progressive failure of followers ...
  ... Passed --   4.5  3  132   27683    3
Test (2B): test failure of leaders ...
  ... Passed --   4.8  3  196   43642    3
Test (2B): agreement after follower reconnects ...
  ... Passed --   5.4  3  128   34029    8
Test (2B): no agreement if too many followers disconnect ...
  ... Passed --   3.5  5  227   47415    3
Test (2B): concurrent Start()s ...
  ... Passed --   0.5  3   22    6335    6
Test (2B): rejoin of partitioned leader ...
  ... Passed --   3.9  3  148   35662    4
Test (2B): leader backs up quickly over incorrect follower logs ...
  ... Passed --  16.5  5 2187 1795164  102
Test (2B): RPC counts aren't too high ...
  ... Passed --   2.1  3   64   18707   12
PASS
ok  	6.5840/raft	43.082s

```

